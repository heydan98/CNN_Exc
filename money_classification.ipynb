{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "C7xuCklZy3-e"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from pathlib import Path\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30HLwevWz1MB",
        "outputId": "10d24bd5-9505-4b52-bbb2-4ca28a462ae2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd \"/content/drive/MyDrive/money_data\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjuhKXph0K1R",
        "outputId": "113fd28a-e0eb-4634-c82b-07bc9ac48ef4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/money_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KomYpf6G0U84",
        "outputId": "9e34e9e8-47a9-446f-91fd-aa38e3d0e9f7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34m100000dong\u001b[0m/  \u001b[01;34m10000dong\u001b[0m/  \u001b[01;34m200000dong\u001b[0m/  \u001b[01;34m20000dong\u001b[0m/  \u001b[01;34m50000dong\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing\n",
        "link = \"/content/drive/MyDrive/money_data\"\n",
        "money_names = os.listdir(link)\n",
        "money_path = []\n",
        "for money_name in money_names:\n",
        "  money_path.append(os.path.join(link, money_name))\n",
        "print(money_names)\n",
        "X = []\n",
        "y = []\n",
        "for i in range(len(money_path)):\n",
        "  print(money_names[i])\n",
        "  img_path = list(Path(money_path[i]).glob(\"*\"))\n",
        "  for j in img_path:\n",
        "    img = plt.imread(j)\n",
        "    img = cv2.resize(img, (128, 128))\n",
        "    img.astype('float32')\n",
        "    img = img/255\n",
        "    X.append(img)\n",
        "    y.append(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-jCIGJt0aQQ",
        "outputId": "a0b84724-67e0-447b-9175-05d26d9d3872"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['10000dong', '20000dong', '50000dong', '100000dong', '200000dong']\n",
            "10000dong\n",
            "20000dong\n",
            "50000dong\n",
            "100000dong\n",
            "200000dong\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGIuMzHC0hfR",
        "outputId": "8027b5d0-73ea-497b-ac9e-60f2b1b5c33e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(954, 128, 128, 3)\n",
            "(954,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "y = to_categorical(y)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rNzDyE30lM4",
        "outputId": "5924210a-7a14-4704-beda-ca39f400bf43"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(954, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "metadata": {
        "id": "HliuWIBa0omo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import models, layers\n",
        "from keras.layers import Flatten, Dense, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils \n",
        "model = models.Sequential()\n",
        "model.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=(128,128,3),padding = 'same'))\n",
        "model.add(MaxPooling2D((2,2),padding='same'))\n",
        "model.add(Conv2D(64,kernel_size=(3,3),activation='relu',padding = 'same'))\n",
        "model.add(MaxPooling2D((2,2),padding='same'))\n",
        "model.add(Conv2D(128,kernel_size=(3,3),activation='relu',padding = 'same'))\n",
        "model.add(MaxPooling2D((2,2),padding='same'))\n",
        "model.add(Flatten(input_shape=[128, 128, 3]))\n",
        "model.add(Dense(2000, activation='relu'))\n",
        "model.add(Dense(1000, activation='relu'))\n",
        "model.add(Dense(3000, activation='relu'))\n",
        "model.add(Dense(2000, activation='relu'))\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(len(money_names), activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_sTENhx0rRw",
        "outputId": "897d715b-3466-465a-c4b8-8f39568ffac0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 128, 128, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 64, 64, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 64, 64, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 32, 32, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 32, 32, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 16, 16, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 32768)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2000)              65538000  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1000)              2001000   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3000)              3003000   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2000)              6002000   \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 500)               1000500   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 100)               50100     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 5)                 505       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 77,688,353\n",
            "Trainable params: 77,688,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "jAhtTkPD0zjQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=300, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0OmgxCC0uYg",
        "outputId": "6c054151-13bb-4b15-f9b3-d48d05c24fbe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "6/6 [==============================] - 6s 306ms/step - loss: 8.4801 - accuracy: 0.3421\n",
            "Epoch 2/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.2221 - accuracy: 0.3840\n",
            "Epoch 3/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.0708 - accuracy: 0.4168\n",
            "Epoch 4/300\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 1.0700 - accuracy: 0.4010\n",
            "Epoch 5/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.0645 - accuracy: 0.4010\n",
            "Epoch 6/300\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 1.0708 - accuracy: 0.3971\n",
            "Epoch 7/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 1.0649 - accuracy: 0.4142\n",
            "Epoch 8/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 1.0619 - accuracy: 0.4168\n",
            "Epoch 9/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.0595 - accuracy: 0.4050\n",
            "Epoch 10/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.1298 - accuracy: 0.3801\n",
            "Epoch 11/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 1.0593 - accuracy: 0.4142\n",
            "Epoch 12/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 1.0645 - accuracy: 0.3932\n",
            "Epoch 13/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.0702 - accuracy: 0.3984\n",
            "Epoch 14/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 1.1603 - accuracy: 0.4089\n",
            "Epoch 15/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 1.0579 - accuracy: 0.4024\n",
            "Epoch 16/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.0472 - accuracy: 0.3997\n",
            "Epoch 17/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 1.0782 - accuracy: 0.3932\n",
            "Epoch 18/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 1.0585 - accuracy: 0.3958\n",
            "Epoch 19/300\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 1.0562 - accuracy: 0.4286\n",
            "Epoch 20/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.0538 - accuracy: 0.4024\n",
            "Epoch 21/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.0570 - accuracy: 0.3814\n",
            "Epoch 22/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.1523 - accuracy: 0.4155\n",
            "Epoch 23/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 1.0671 - accuracy: 0.3866\n",
            "Epoch 24/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.0482 - accuracy: 0.4312\n",
            "Epoch 25/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 1.0461 - accuracy: 0.4246\n",
            "Epoch 26/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.0469 - accuracy: 0.4260\n",
            "Epoch 27/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.0811 - accuracy: 0.3919\n",
            "Epoch 28/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.0640 - accuracy: 0.4299\n",
            "Epoch 29/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 1.0533 - accuracy: 0.4128\n",
            "Epoch 30/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 1.0427 - accuracy: 0.4142\n",
            "Epoch 31/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 1.0423 - accuracy: 0.4273\n",
            "Epoch 32/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 1.0530 - accuracy: 0.4050\n",
            "Epoch 33/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.0542 - accuracy: 0.4286\n",
            "Epoch 34/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 1.0486 - accuracy: 0.4325\n",
            "Epoch 35/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 1.3617 - accuracy: 0.4181\n",
            "Epoch 36/300\n",
            "6/6 [==============================] - 1s 111ms/step - loss: 1.0534 - accuracy: 0.3893\n",
            "Epoch 37/300\n",
            "6/6 [==============================] - 1s 117ms/step - loss: 1.0479 - accuracy: 0.4286\n",
            "Epoch 38/300\n",
            "6/6 [==============================] - 1s 116ms/step - loss: 1.0403 - accuracy: 0.4286\n",
            "Epoch 39/300\n",
            "6/6 [==============================] - 1s 113ms/step - loss: 1.1188 - accuracy: 0.3814\n",
            "Epoch 40/300\n",
            "6/6 [==============================] - 1s 112ms/step - loss: 1.0330 - accuracy: 0.4181\n",
            "Epoch 41/300\n",
            "6/6 [==============================] - 1s 110ms/step - loss: 1.3378 - accuracy: 0.3722\n",
            "Epoch 42/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 1.0395 - accuracy: 0.4718\n",
            "Epoch 43/300\n",
            "6/6 [==============================] - 1s 111ms/step - loss: 1.0342 - accuracy: 0.4875\n",
            "Epoch 44/300\n",
            "6/6 [==============================] - 1s 111ms/step - loss: 0.9748 - accuracy: 0.5885\n",
            "Epoch 45/300\n",
            "6/6 [==============================] - 1s 114ms/step - loss: 1.2767 - accuracy: 0.5426\n",
            "Epoch 46/300\n",
            "6/6 [==============================] - 1s 109ms/step - loss: 0.5676 - accuracy: 0.6776\n",
            "Epoch 47/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 1.2446 - accuracy: 0.4299\n",
            "Epoch 48/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 0.8116 - accuracy: 0.6540\n",
            "Epoch 49/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 0.5176 - accuracy: 0.6855\n",
            "Epoch 50/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.4490 - accuracy: 0.7235\n",
            "Epoch 51/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.5882 - accuracy: 0.6907\n",
            "Epoch 52/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 0.4484 - accuracy: 0.7733\n",
            "Epoch 53/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 0.4002 - accuracy: 0.7575\n",
            "Epoch 54/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 0.5315 - accuracy: 0.7759\n",
            "Epoch 55/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 0.4257 - accuracy: 0.8021\n",
            "Epoch 56/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 0.4826 - accuracy: 0.7733\n",
            "Epoch 57/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 0.3790 - accuracy: 0.8388\n",
            "Epoch 58/300\n",
            "6/6 [==============================] - 1s 110ms/step - loss: 0.2785 - accuracy: 0.8899\n",
            "Epoch 59/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 0.3808 - accuracy: 0.8218\n",
            "Epoch 60/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 0.2213 - accuracy: 0.9318\n",
            "Epoch 61/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.1979 - accuracy: 0.9240\n",
            "Epoch 62/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 0.3352 - accuracy: 0.8860\n",
            "Epoch 63/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.0753 - accuracy: 0.9803\n",
            "Epoch 64/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 0.0392 - accuracy: 0.9895\n",
            "Epoch 65/300\n",
            "6/6 [==============================] - 1s 110ms/step - loss: 0.4779 - accuracy: 0.7864\n",
            "Epoch 66/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 0.1641 - accuracy: 0.9646\n",
            "Epoch 67/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 0.2112 - accuracy: 0.9384\n",
            "Epoch 68/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.1008 - accuracy: 0.9659\n",
            "Epoch 69/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 0.1679 - accuracy: 0.9423\n",
            "Epoch 70/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.1162 - accuracy: 0.9554\n",
            "Epoch 71/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.0647 - accuracy: 0.9764\n",
            "Epoch 72/300\n",
            "6/6 [==============================] - 1s 109ms/step - loss: 0.0294 - accuracy: 0.9895\n",
            "Epoch 73/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 0.0290 - accuracy: 0.9908\n",
            "Epoch 74/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 0.0304 - accuracy: 0.9921\n",
            "Epoch 75/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.6043 - accuracy: 0.8978\n",
            "Epoch 76/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.1356 - accuracy: 0.9607\n",
            "Epoch 77/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.0809 - accuracy: 0.9817\n",
            "Epoch 78/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.0194 - accuracy: 0.9934\n",
            "Epoch 79/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.0375 - accuracy: 0.9895\n",
            "Epoch 80/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.0164 - accuracy: 0.9934\n",
            "Epoch 81/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 0.0594 - accuracy: 0.9817\n",
            "Epoch 82/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.0099 - accuracy: 0.9948\n",
            "Epoch 83/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.0331 - accuracy: 0.9921\n",
            "Epoch 84/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 1.3882 - accuracy: 0.7038\n",
            "Epoch 85/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 1.1853 - accuracy: 0.9135\n",
            "Epoch 86/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 0.0840 - accuracy: 0.9633\n",
            "Epoch 87/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.0655 - accuracy: 0.9751\n",
            "Epoch 88/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.0850 - accuracy: 0.9699\n",
            "Epoch 89/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.0244 - accuracy: 0.9921\n",
            "Epoch 90/300\n",
            "6/6 [==============================] - 1s 119ms/step - loss: 0.0916 - accuracy: 0.9738\n",
            "Epoch 91/300\n",
            "6/6 [==============================] - 1s 115ms/step - loss: 0.0148 - accuracy: 0.9974\n",
            "Epoch 92/300\n",
            "6/6 [==============================] - 1s 111ms/step - loss: 0.1329 - accuracy: 0.9803\n",
            "Epoch 93/300\n",
            "6/6 [==============================] - 1s 120ms/step - loss: 1.2498 - accuracy: 0.7510\n",
            "Epoch 94/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.0663 - accuracy: 0.9843\n",
            "Epoch 95/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.0123 - accuracy: 0.9948\n",
            "Epoch 96/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 0.0895 - accuracy: 0.9685\n",
            "Epoch 97/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 0.0519 - accuracy: 0.9908\n",
            "Epoch 98/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.0094 - accuracy: 0.9974\n",
            "Epoch 99/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.0667 - accuracy: 0.9803\n",
            "Epoch 100/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.5595 - accuracy: 0.9109\n",
            "Epoch 101/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.0407 - accuracy: 0.9934\n",
            "Epoch 102/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 0.0148 - accuracy: 0.9934\n",
            "Epoch 103/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.0139 - accuracy: 0.9961\n",
            "Epoch 104/300\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 7.4418e-04 - accuracy: 1.0000\n",
            "Epoch 105/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.9739e-04 - accuracy: 1.0000\n",
            "Epoch 106/300\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 7.6282e-05 - accuracy: 1.0000\n",
            "Epoch 107/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 4.0870e-05 - accuracy: 1.0000\n",
            "Epoch 108/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 2.1754e-05 - accuracy: 1.0000\n",
            "Epoch 109/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.1487e-05 - accuracy: 1.0000\n",
            "Epoch 110/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 6.2258e-06 - accuracy: 1.0000\n",
            "Epoch 111/300\n",
            "6/6 [==============================] - 1s 109ms/step - loss: 3.6107e-06 - accuracy: 1.0000\n",
            "Epoch 112/300\n",
            "6/6 [==============================] - 1s 109ms/step - loss: 2.3243e-06 - accuracy: 1.0000\n",
            "Epoch 113/300\n",
            "6/6 [==============================] - 1s 113ms/step - loss: 1.5670e-06 - accuracy: 1.0000\n",
            "Epoch 114/300\n",
            "6/6 [==============================] - 1s 113ms/step - loss: 1.0644e-06 - accuracy: 1.0000\n",
            "Epoch 115/300\n",
            "6/6 [==============================] - 1s 109ms/step - loss: 7.0524e-07 - accuracy: 1.0000\n",
            "Epoch 116/300\n",
            "6/6 [==============================] - 1s 111ms/step - loss: 5.0198e-07 - accuracy: 1.0000\n",
            "Epoch 117/300\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 3.5606e-07 - accuracy: 1.0000\n",
            "Epoch 118/300\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 2.5638e-07 - accuracy: 1.0000\n",
            "Epoch 119/300\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 1.8280e-07 - accuracy: 1.0000\n",
            "Epoch 120/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.3218e-07 - accuracy: 1.0000\n",
            "Epoch 121/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.0343e-07 - accuracy: 1.0000\n",
            "Epoch 122/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 7.7337e-08 - accuracy: 1.0000\n",
            "Epoch 123/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 5.8433e-08 - accuracy: 1.0000\n",
            "Epoch 124/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 4.5309e-08 - accuracy: 1.0000\n",
            "Epoch 125/300\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 3.5466e-08 - accuracy: 1.0000\n",
            "Epoch 126/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 2.7029e-08 - accuracy: 1.0000\n",
            "Epoch 127/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 2.2342e-08 - accuracy: 1.0000\n",
            "Epoch 128/300\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 1.8436e-08 - accuracy: 1.0000\n",
            "Epoch 129/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.4686e-08 - accuracy: 1.0000\n",
            "Epoch 130/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.2655e-08 - accuracy: 1.0000\n",
            "Epoch 131/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 8.2806e-09 - accuracy: 1.0000\n",
            "Epoch 132/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 6.7182e-09 - accuracy: 1.0000\n",
            "Epoch 133/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 5.7808e-09 - accuracy: 1.0000\n",
            "Epoch 134/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 5.3121e-09 - accuracy: 1.0000\n",
            "Epoch 135/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 5.1558e-09 - accuracy: 1.0000\n",
            "Epoch 136/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 2.6560e-09 - accuracy: 1.0000\n",
            "Epoch 137/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 3.7497e-09 - accuracy: 1.0000\n",
            "Epoch 138/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.7186e-09 - accuracy: 1.0000\n",
            "Epoch 139/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 1.2499e-09 - accuracy: 1.0000\n",
            "Epoch 140/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 2.1873e-09 - accuracy: 1.0000\n",
            "Epoch 141/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 7.8119e-10 - accuracy: 1.0000\n",
            "Epoch 142/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 6.2495e-10 - accuracy: 1.0000\n",
            "Epoch 143/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 6.2495e-10 - accuracy: 1.0000\n",
            "Epoch 144/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 9.3743e-10 - accuracy: 1.0000\n",
            "Epoch 145/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 6.7182e-09 - accuracy: 1.0000\n",
            "Epoch 146/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 4.7435 - accuracy: 0.7261\n",
            "Epoch 147/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.1924 - accuracy: 0.9332\n",
            "Epoch 148/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 0.0113 - accuracy: 0.9948\n",
            "Epoch 149/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 150/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 151/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 2.6228e-04 - accuracy: 1.0000\n",
            "Epoch 152/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 2.0697e-04 - accuracy: 1.0000\n",
            "Epoch 153/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 2.8305e-05 - accuracy: 1.0000\n",
            "Epoch 154/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.5159e-05 - accuracy: 1.0000\n",
            "Epoch 155/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 9.1431e-06 - accuracy: 1.0000\n",
            "Epoch 156/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 5.4541e-06 - accuracy: 1.0000\n",
            "Epoch 157/300\n",
            "6/6 [==============================] - 1s 109ms/step - loss: 3.5530e-06 - accuracy: 1.0000\n",
            "Epoch 158/300\n",
            "6/6 [==============================] - 1s 109ms/step - loss: 2.3177e-06 - accuracy: 1.0000\n",
            "Epoch 159/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.5495e-06 - accuracy: 1.0000\n",
            "Epoch 160/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 1.0454e-06 - accuracy: 1.0000\n",
            "Epoch 161/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 7.3165e-07 - accuracy: 1.0000\n",
            "Epoch 162/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 5.2495e-07 - accuracy: 1.0000\n",
            "Epoch 163/300\n",
            "6/6 [==============================] - 1s 109ms/step - loss: 3.8340e-07 - accuracy: 1.0000\n",
            "Epoch 164/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 2.7591e-07 - accuracy: 1.0000\n",
            "Epoch 165/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 2.1248e-07 - accuracy: 1.0000\n",
            "Epoch 166/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 1.5592e-07 - accuracy: 1.0000\n",
            "Epoch 167/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 1.1921e-07 - accuracy: 1.0000\n",
            "Epoch 168/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 9.1867e-08 - accuracy: 1.0000\n",
            "Epoch 169/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 7.0932e-08 - accuracy: 1.0000\n",
            "Epoch 170/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 5.8589e-08 - accuracy: 1.0000\n",
            "Epoch 171/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 4.6403e-08 - accuracy: 1.0000\n",
            "Epoch 172/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 3.5935e-08 - accuracy: 1.0000\n",
            "Epoch 173/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 3.0623e-08 - accuracy: 1.0000\n",
            "Epoch 174/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 2.3592e-08 - accuracy: 1.0000\n",
            "Epoch 175/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 1.9686e-08 - accuracy: 1.0000\n",
            "Epoch 176/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 1.5780e-08 - accuracy: 1.0000\n",
            "Epoch 177/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 1.1874e-08 - accuracy: 1.0000\n",
            "Epoch 178/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 9.3743e-09 - accuracy: 1.0000\n",
            "Epoch 179/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 7.4994e-09 - accuracy: 1.0000\n",
            "Epoch 180/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 4.9996e-09 - accuracy: 1.0000\n",
            "Epoch 181/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 4.2184e-09 - accuracy: 1.0000\n",
            "Epoch 182/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 3.9059e-09 - accuracy: 1.0000\n",
            "Epoch 183/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 2.6560e-09 - accuracy: 1.0000\n",
            "Epoch 184/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 1.8749e-09 - accuracy: 1.0000\n",
            "Epoch 185/300\n",
            "6/6 [==============================] - 1s 109ms/step - loss: 2.0311e-09 - accuracy: 1.0000\n",
            "Epoch 186/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 2.4998e-09 - accuracy: 1.0000\n",
            "Epoch 187/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 6.2495e-10 - accuracy: 1.0000\n",
            "Epoch 188/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 7.8119e-10 - accuracy: 1.0000\n",
            "Epoch 189/300\n",
            "6/6 [==============================] - 1s 112ms/step - loss: 1.8749e-09 - accuracy: 1.0000\n",
            "Epoch 190/300\n",
            "6/6 [==============================] - 1s 111ms/step - loss: 4.3385 - accuracy: 0.8650\n",
            "Epoch 191/300\n",
            "6/6 [==============================] - 1s 113ms/step - loss: 1.3050 - accuracy: 0.5636\n",
            "Epoch 192/300\n",
            "6/6 [==============================] - 1s 116ms/step - loss: 0.1942 - accuracy: 0.9305\n",
            "Epoch 193/300\n",
            "6/6 [==============================] - 1s 114ms/step - loss: 0.0349 - accuracy: 0.9908\n",
            "Epoch 194/300\n",
            "6/6 [==============================] - 1s 112ms/step - loss: 0.0269 - accuracy: 0.9882\n",
            "Epoch 195/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.0227 - accuracy: 0.9895\n",
            "Epoch 196/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 0.1281 - accuracy: 0.9410\n",
            "Epoch 197/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 0.2719 - accuracy: 0.8060\n",
            "Epoch 198/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 0.1193 - accuracy: 0.9882\n",
            "Epoch 199/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 0.0422 - accuracy: 0.9830\n",
            "Epoch 200/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 0.0083 - accuracy: 0.9974\n",
            "Epoch 201/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 0.0062 - accuracy: 0.9961\n",
            "Epoch 202/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 9.4497e-04 - accuracy: 1.0000\n",
            "Epoch 203/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 204/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 2.1335 - accuracy: 0.8283\n",
            "Epoch 205/300\n",
            "6/6 [==============================] - 1s 109ms/step - loss: 0.0887 - accuracy: 0.9895\n",
            "Epoch 206/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.0042 - accuracy: 0.9987\n",
            "Epoch 207/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 4.5009e-04 - accuracy: 1.0000\n",
            "Epoch 208/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 1.5647e-04 - accuracy: 1.0000\n",
            "Epoch 209/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 7.2935e-05 - accuracy: 1.0000\n",
            "Epoch 210/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 3.7407e-05 - accuracy: 1.0000\n",
            "Epoch 211/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 2.0527e-05 - accuracy: 1.0000\n",
            "Epoch 212/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.2449e-05 - accuracy: 1.0000\n",
            "Epoch 213/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 8.3093e-06 - accuracy: 1.0000\n",
            "Epoch 214/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 4.5604e-06 - accuracy: 1.0000\n",
            "Epoch 215/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 2.9662e-06 - accuracy: 1.0000\n",
            "Epoch 216/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 2.0341e-06 - accuracy: 1.0000\n",
            "Epoch 217/300\n",
            "6/6 [==============================] - 1s 109ms/step - loss: 1.4609e-06 - accuracy: 1.0000\n",
            "Epoch 218/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 9.5818e-07 - accuracy: 1.0000\n",
            "Epoch 219/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 7.2430e-07 - accuracy: 1.0000\n",
            "Epoch 220/300\n",
            "6/6 [==============================] - 1s 109ms/step - loss: 5.2854e-07 - accuracy: 1.0000\n",
            "Epoch 221/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 3.7137e-07 - accuracy: 1.0000\n",
            "Epoch 222/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 2.8732e-07 - accuracy: 1.0000\n",
            "Epoch 223/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 2.2201e-07 - accuracy: 1.0000\n",
            "Epoch 224/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.6967e-07 - accuracy: 1.0000\n",
            "Epoch 225/300\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 1.3811e-07 - accuracy: 1.0000\n",
            "Epoch 226/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.0577e-07 - accuracy: 1.0000\n",
            "Epoch 227/300\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 8.2649e-08 - accuracy: 1.0000\n",
            "Epoch 228/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 6.5151e-08 - accuracy: 1.0000\n",
            "Epoch 229/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 5.6402e-08 - accuracy: 1.0000\n",
            "Epoch 230/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 4.4684e-08 - accuracy: 1.0000\n",
            "Epoch 231/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 3.3122e-08 - accuracy: 1.0000\n",
            "Epoch 232/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 2.7498e-08 - accuracy: 1.0000\n",
            "Epoch 233/300\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 2.3748e-08 - accuracy: 1.0000\n",
            "Epoch 234/300\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 2.2029e-08 - accuracy: 1.0000\n",
            "Epoch 235/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 1.6092e-08 - accuracy: 1.0000\n",
            "Epoch 236/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.1249e-08 - accuracy: 1.0000\n",
            "Epoch 237/300\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 7.9681e-09 - accuracy: 1.0000\n",
            "Epoch 238/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 6.4057e-09 - accuracy: 1.0000\n",
            "Epoch 239/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 4.9996e-09 - accuracy: 1.0000\n",
            "Epoch 240/300\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 4.9996e-09 - accuracy: 1.0000\n",
            "Epoch 241/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 3.5935e-09 - accuracy: 1.0000\n",
            "Epoch 242/300\n",
            "6/6 [==============================] - 1s 104ms/step - loss: 4.9996e-09 - accuracy: 1.0000\n",
            "Epoch 243/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 2.4998e-09 - accuracy: 1.0000\n",
            "Epoch 244/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 0.0152 - accuracy: 0.9987\n",
            "Epoch 245/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 8.5819 - accuracy: 0.7195\n",
            "Epoch 246/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 0.1337 - accuracy: 0.9463\n",
            "Epoch 247/300\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 0.0346 - accuracy: 0.9830\n",
            "Epoch 248/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 4.9457e-04 - accuracy: 1.0000\n",
            "Epoch 249/300\n",
            "6/6 [==============================] - 1s 109ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 250/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.1108 - accuracy: 0.9830\n",
            "Epoch 251/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 252/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 4.6205e-04 - accuracy: 1.0000\n",
            "Epoch 253/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 2.0731e-04 - accuracy: 1.0000\n",
            "Epoch 254/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 9.9414e-05 - accuracy: 1.0000\n",
            "Epoch 255/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 5.4384e-05 - accuracy: 1.0000\n",
            "Epoch 256/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 3.2471e-05 - accuracy: 1.0000\n",
            "Epoch 257/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 1.8924e-05 - accuracy: 1.0000\n",
            "Epoch 258/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 1.1639e-05 - accuracy: 1.0000\n",
            "Epoch 259/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 7.3714e-06 - accuracy: 1.0000\n",
            "Epoch 260/300\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 4.6894e-06 - accuracy: 1.0000\n",
            "Epoch 261/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 3.5257e-06 - accuracy: 1.0000\n",
            "Epoch 262/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 2.2708e-06 - accuracy: 1.0000\n",
            "Epoch 263/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 1.6023e-06 - accuracy: 1.0000\n",
            "Epoch 264/300\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 1.1773e-06 - accuracy: 1.0000\n",
            "Epoch 265/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 8.2959e-07 - accuracy: 1.0000\n",
            "Epoch 266/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 6.1040e-07 - accuracy: 1.0000\n",
            "Epoch 267/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 4.6152e-07 - accuracy: 1.0000\n",
            "Epoch 268/300\n",
            "6/6 [==============================] - 1s 111ms/step - loss: 3.5387e-07 - accuracy: 1.0000\n",
            "Epoch 269/300\n",
            "6/6 [==============================] - 1s 115ms/step - loss: 2.6044e-07 - accuracy: 1.0000\n",
            "Epoch 270/300\n",
            "6/6 [==============================] - 1s 115ms/step - loss: 2.1482e-07 - accuracy: 1.0000\n",
            "Epoch 271/300\n",
            "6/6 [==============================] - 1s 114ms/step - loss: 1.6327e-07 - accuracy: 1.0000\n",
            "Epoch 272/300\n",
            "6/6 [==============================] - 1s 112ms/step - loss: 1.3030e-07 - accuracy: 1.0000\n",
            "Epoch 273/300\n",
            "6/6 [==============================] - 1s 110ms/step - loss: 1.0593e-07 - accuracy: 1.0000\n",
            "Epoch 274/300\n",
            "6/6 [==============================] - 1s 105ms/step - loss: 8.0774e-08 - accuracy: 1.0000\n",
            "Epoch 275/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 6.4682e-08 - accuracy: 1.0000\n",
            "Epoch 276/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 6.7807e-08 - accuracy: 1.0000\n",
            "Epoch 277/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 4.1872e-08 - accuracy: 1.0000\n",
            "Epoch 278/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 3.4997e-08 - accuracy: 1.0000\n",
            "Epoch 279/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 2.7342e-08 - accuracy: 1.0000\n",
            "Epoch 280/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 2.3123e-08 - accuracy: 1.0000\n",
            "Epoch 281/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.8124e-08 - accuracy: 1.0000\n",
            "Epoch 282/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 1.6405e-08 - accuracy: 1.0000\n",
            "Epoch 283/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 1.3124e-08 - accuracy: 1.0000\n",
            "Epoch 284/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 1.0468e-08 - accuracy: 1.0000\n",
            "Epoch 285/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 8.5931e-09 - accuracy: 1.0000\n",
            "Epoch 286/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 8.2806e-09 - accuracy: 1.0000\n",
            "Epoch 287/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 9.3742e-09 - accuracy: 1.0000\n",
            "Epoch 288/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 4.5309e-09 - accuracy: 1.0000\n",
            "Epoch 289/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 3.4372e-09 - accuracy: 1.0000\n",
            "Epoch 290/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 3.4372e-09 - accuracy: 1.0000\n",
            "Epoch 291/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 2.4998e-09 - accuracy: 1.0000\n",
            "Epoch 292/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 2.0311e-09 - accuracy: 1.0000\n",
            "Epoch 293/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 1.8749e-09 - accuracy: 1.0000\n",
            "Epoch 294/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 1.2499e-09 - accuracy: 1.0000\n",
            "Epoch 295/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 9.3743e-10 - accuracy: 1.0000\n",
            "Epoch 296/300\n",
            "6/6 [==============================] - 1s 109ms/step - loss: 1.0937e-09 - accuracy: 1.0000\n",
            "Epoch 297/300\n",
            "6/6 [==============================] - 1s 108ms/step - loss: 11.9979 - accuracy: 0.6239\n",
            "Epoch 298/300\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 0.7681 - accuracy: 0.7851\n",
            "Epoch 299/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 0.0069 - accuracy: 0.9987\n",
            "Epoch 300/300\n",
            "6/6 [==============================] - 1s 106ms/step - loss: 0.0026 - accuracy: 0.9987\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f309a3eb790>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = 123\n",
        "print(f'{n}/{len(y_test)}')\n",
        "pred = model.predict(X_test[n].reshape((1, 128, 128, 3)))\n",
        "print(f'Predict: {money_names[pred.argmax()]}  ({int(pred[0][pred.argmax()]*100)}%)')\n",
        "print('True_label: ', money_names[y_test[n].argmax()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0B_-08w05_4",
        "outputId": "dd35e287-a806-4549-e6c1-f47b6ca7a62a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "123/191\n",
            "1/1 [==============================] - 0s 202ms/step\n",
            "Predict: 20000dong  (100%)\n",
            "True_label:  20000dong\n"
          ]
        }
      ]
    }
  ]
}